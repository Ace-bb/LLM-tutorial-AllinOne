> 原文地址 [www.zhihu.com](https://www.zhihu.com/question/599396505/answer/3583853852)

老生常谈的一句话吧：有没有技术含量取决于这个工作你怎么做，尤其是 [llm](https://www.zhihu.com/search?q=llm&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 方向，上手门槛相比传统 [NLP](https://www.zhihu.com/search?q=NLP&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 变得更低了。

我举一些例子吧，针对大模型微调的几个重要环节，我列举的每一种做法大概率都能完成最终目标，甚至说训出来的模型效果都没什么差别。但对个人能力成长的帮助就大不相同了。

### 数据工作

**做法 1** : 继承实验室或者同事的训练数据，拿到之后也不 check 一下数据质量，直接放进去训。

**做法 2** : 下载一个[开源数据](https://www.zhihu.com/search?q=%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D)，构建“system + query + [answer](https://www.zhihu.com/search?q=answer&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D)”集合。

**做法 3** : 利用 [gpt4](https://www.zhihu.com/search?q=gpt4&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 生成数据，学会用 gpt4 喜好的 [prompt](https://www.zhihu.com/search?q=prompt&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 去请求。并且意识到数据 prompt 多样性，想尽各种办法去扩充 prompt 的任务多样性和表达方式多样性，甚至去刻意加一些 noisy prompt 去提升抗噪性。同时，愿意放下身架，一条一条去 check 数据质量，去和标注同学对齐标注标准。

**做法 4** : 利用用户的交互日志来驱动数据构造过程，收集用户的真实 prompt，用规则或者[GPT4](https://www.zhihu.com/search?q=GPT4&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D)去分析用户的 feedback，进而获得高质量的 answer 数据。

**做法 5** : 借鉴 cot、rag、 function_call、agent 等思路，把复杂的模型无法胜任的任务在数据层面就进行拆解，比如“模型写不出长篇小说” --> “模型写小说大纲，模型基于小说大纲写长篇小说”。

……

### 训练代码

**做法 1** : 继承实验室或者同事的训练代码，修改 [data_path](https://www.zhihu.com/search?q=data_path&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D)，然后 bash train.sh。

**做法 2** : 继承或自己下载一份训练代码，研究[启动代码](https://www.zhihu.com/search?q=%E5%90%AF%E5%8A%A8%E4%BB%A3%E7%A0%81&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D)的每一个参数，去寻思并去搞懂：为啥开 offload，什么叫 sequence_parallel，等等。然后再去看看 [dataloader](https://www.zhihu.com/search?q=dataloader&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 是怎么处理数据格式，session 数据的 loss 是只计算最后一轮还是每轮都算，代码中应用了哪些 special_token 等等。

**做法 3** : 不仅搞懂了每个参数，还提出自己的见解：[epoch](https://www.zhihu.com/search?q=epoch&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) = 3 是不是太多了，10W 条训练数据这个量级合适吗？special_token 是不是引入的太多了？7B 模型用这个学习率是不是太大了，[warmup](https://www.zhihu.com/search?q=warmup&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 该用多少 step 或者说能不能不开 warmup？带着疑惑然后去问问 [chatgpt](https://www.zhihu.com/search?q=chatgpt&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 老师怎么说，或者搜搜大佬们的文章拜读一下。

**做法 4** : 质疑和改进训练代码，[deepspeed](https://www.zhihu.com/search?q=deepspeed&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 是不是有点慢，要不要改成 [megatron](https://www.zhihu.com/search?q=megatron&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 框架？把 megatron 和 deepspeed 的优点结合起来？如果有兴趣，也可以去 debug 下速度， 发现 [rope](https://www.zhihu.com/search?q=rope&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 的耗时会比 attention 都长的时候想想办法去优化（查查大佬们的优化方案）？

……

### 实验分析

**做法 1** : 跑事前准备好的评估集，然后自评或送评，正向收益的话这个工作纠结束了，负向收益的话就认为是数据不干净，想办法去清洗数据或者是构造更多的训练数据，哪个 task 的[指标差](https://www.zhihu.com/search?q=%E6%8C%87%E6%A0%87%E5%B7%AE&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D)就重点优化这个 task 的训练数据。

**做法 2** : 结合 [pretrain 模型](https://www.zhihu.com/search?q=pretrain%20%E6%A8%A1%E5%9E%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) / sft_base 模型的结果，去归类和分析每一个 [sft_exp](https://www.zhihu.com/search?q=sft_exp&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 模型的 bad case，归类分析：幻觉问题？pattern [过拟合](https://www.zhihu.com/search?q=%E8%BF%87%E6%8B%9F%E5%90%88&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D)问题？问题太难训练不充分问题？pretrain模型压根就没有这个能力？这个 size 的模型就做不了这种复杂逻辑问题？……

针对自己的分析结果，设计实验去验证。怀疑某个 task 欠拟合，就上采样这个 task 的数据；怀疑是训过拟合了，就抽一些训练数据的 [prompt 格式](https://www.zhihu.com/search?q=prompt%20%E6%A0%BC%E5%BC%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D)，让模型去回答类似的问题；不知道 7B 模型能不能解决好这个任务，就去下载 llama、qwen、mistral、[deepspeek](https://www.zhihu.com/search?q=deepspeek&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 等同 size 的 [chat 模型](https://www.zhihu.com/search?q=chat%20%E6%A8%A1%E5%9E%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D)去验证效果；等等等等。

这个过程要往往要积攒一些经验，学会一些小 trick：

*   让 pretrain 模型去续写，来判断某个能力或某个知识是模型压根没有，还是说被自己训没了；
*   观察某个 token 的概率；
*   观察模型在第几个 [token](https://www.zhihu.com/search?q=token&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 开始回答错误的；
*   如果模型的 [pattern](https://www.zhihu.com/search?q=pattern&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 输出错误，比如没有按照 [json](https://www.zhihu.com/search?q=json&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 输出，看一下是不会 json，还是不知道该出 json，可以把**```json````**也喂给模型，看模型的续写情况；
*   模型把“日本的首都回答成了北京“了，不要直接断言是幻觉，而是分析下模型是对“日本””首都“”北京“哪个 token 过拟合了，有可能是模型把所有国家的首都都回答成北京，也有可能模型是把日本的任何城市都回答成北京。进而看下[训练集](https://www.zhihu.com/search?q=%E8%AE%AD%E7%BB%83%E9%9B%86&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D)和这个 pattern 有关的语料是不是太多了；
*   ……

**做法 3** : 不仅意识到模型结果和数据质量有关，还去分析和[训练方法](https://www.zhihu.com/search?q=%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D)的关系。结合训练日志、[tensorboad](https://www.zhihu.com/search?q=tensorboad&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 和模型的评估结果，去共同分析模型效果。SFT 的初始 loss 这么高是为什么、special_token 太多还是训练集的创作任务太多？最终 loss 又是多少、低于 0.5 就要担心过拟合了？[channel_loss](https://www.zhihu.com/search?q=channel_loss&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3583853852%7D) 是否符合预期？SFT 的阶梯形 loss 代表了什么？3 个 epoch 和 2 个 epoch 的效果对比？

**做法 4** : 跑一些 benchmark，去验证模型的通用能力，看看模型是否在通用能力上明显下降，或者说哪种通用能力下降了？进而分析，为什么自己训 task A 会导致数学能力下降？自己训 task B 会导致创作能力下降？想办法去研究通用能力的跷跷板问题，去避免学着忘着的尴尬现象。

……

* * *

并不是说以上的“做法1”是不对的，我自己也有过很多次的“做法1”，毕竟相信前辈往往都能有不错的结果。我只是想强调：SFT这个方向有没有技术含量，还是要看自己的定位和做法。