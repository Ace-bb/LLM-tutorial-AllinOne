
### 经验

我最常听到的候选人（尤其是学生）的说辞是：我没有大模型经验，可以给个机会吗？

答案是，我们并不看重候选人的大模型训练经验。这里不是说经验不重要，而是大部分人的经验没有意义。只有头部大模型公司的核心骨干的经验才有意义，而这和绝大多数人选无关（e.g.: 校招 / 实习常见的简历是微调 LLaMA 7B，社招常见的简历是各个公司自己的 XX 大模型）。

事实上，平平无奇的大模型经验反而是扣分项。候选人说自己有大模型训练经验，我会问：你说你有千卡训练 XX B 模型的经验，用的是什么并行配置，DP/PP/TP 如何划分？很多时候，我得到的回答是：我不知道。甚至有时候，候选人会问我，什么是 DP，我实在是无言以对。做 CV 的候选人还能背两句 DP 和 DDP 区别的八股，做 NLP 的候选人，在最需要并行的研究领域，却完全不知道 DP 是什么。类似地，如果候选人做过大模型训练，却不知道什么是 MFU，不知道 Megatron 启动的命令行参数含义是什么 [[1]](#ref_1)…… 都属于负分经历。

### 论文

现在不比以前，很多人都有顶会论文。就像大家日常吐槽的一样，90% 的论文都是废纸。特别亮眼的文章自然是加分项，例如 PEFT（Parameter-Efficient Fine-Tuning）方向，最近的 LoRA-GA 和 LoRA-pro 都是不错的文章，但大部分改网络结构讲故事的普通论文是不加分的。如果你有论文，那么说明你经过了基本的科研训练，仅此而已。MSRA 之前招聘实习生有时甚至还会倾向于招聘没做过科研的白纸，因为怕之前短平快的科研经历把候选人的品味带歪了，掰不过来。

### 除了经验和论文，还能看什么

用一个词来概括，是潜力。潜力这个词太虚，这里换成两个词来描述：基础、好奇心。

**什么是基础？**对于学生来说，首要的自然是学习。学校背景如何、专业课成绩如何、基础知识是否扎实？面试时遇到学生，经常碰到的尴尬场面是：问数学题（高数 / 线代 / 概统），答曰大一学的忘了；问编程题（leetcode easy/medium 难度），答曰没刷题写不了；问模型结构（指 LLaMA），答曰平常都是调 ChatGPT API，不清楚。相当一部分候选人是答不上来 transformer 模型结构的——一半人承认自己不清楚细节，另一半人里 90% 是自以为自己知道、但实际不知道。

大部分科研人的代码能力孱弱到只会调 ChatGPT API，或者改改 torch.nn.Module，或者调用开源框架跑跑 SFT/RLHF。分不清楚进程和线程，操作系统背完就忘；编程语言只会一些最基本的 Python，其他语言一概不通。是的，我知道这不影响你发论文，不影响你毕业，git clone 一下开源代码改两行就能满足你的需求嘛。但是，如果你想做改变世界的研究呢？例如，穿越回 2016 年，你想到了 AlphaGo 的 idea，给你足够的计算资源，你有信心自己动手实现它吗？

**什么是好奇心？**没有大模型经验没关系，但是你愿意主动去了解吗？你会去主动读大模型的论文吗？可惜很多候选人不去读。甚至别说读论文，有些想转行大模型的人连大模型用都不用一下。ChatGPT 能解决什么问题、不能解决什么问题？它的能力边界在哪里？一问一个不知道。有时候跟一些候选人保持联系了几个月，但是对方对大模型的了解在几个月的时间里没有任何长进，实在是令人惋惜。如果没机会训练 100B 以上的模型，甚至没有机会训练 7B 的模型，你愿意去下载和分析别人训好的 7B 乃至 1B 的模型，看看里面权重分布的规律吗？如果有这个细腻的心思，可能你在模型量化方面已经做出了很好的工作。

也有时候，基础和好奇心可以互补。例如模型训练刚开始时的 loss 大约是多少？如果数学基础扎实，那么可以做一些合理的假设推导出来；如果好奇心强，会注意观察每一个细节，也能答对这道题。

最后，再介绍一些比普普通通的大模型训练经验和论文更加分的经历的具体例子：

A. 在两张 2080Ti 上实现和比较过不同的流水算法的性能；

B. 用 Triton 自己实现过一些算子；

C. 能讲出不同的大模型使用的 tokenizer 的差异；

D. 在 Python 以外的语言上有不错的开发能力（例如某些开源项目背书）；

E. 实现过一个效果拔群的五子棋 AI（最好是 RL 算法）。

参考
--

1.  [^](#ref_1_0) 这里指候选人说自己用 Megatron 训练，但是是组里的师兄 / 公司的导师给了自己一条启动命令，但是自己不知道每个参数的含义的情况。
